{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import ast\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "path_root = '/mnt/TERA/Data/reddit_topics'\n",
    "path_data = join(path_root, 'safe_links_all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mangling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, filter and save as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = ['.jpg', '.png']\n",
    "df = []\n",
    "with open(path_data, 'r') as f:\n",
    "    for n, line in enumerate(f):\n",
    "        #print(f'\\r{n}', end='')\n",
    "        try:\n",
    "            lst = ast.literal_eval(line)  # [subreddit, submission title, submitted link, comments link, short name]\n",
    "        except ValueError:\n",
    "            #print('ValueError')\n",
    "            continue\n",
    "        if any([x in lst[2] for x in image_types]): \n",
    "            df.append(lst)\n",
    "        if len(df) > 10000:  # testing with a lot smaller dataset first\n",
    "            break\n",
    "            \n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['subreddit', 'submission_title', 'submission_link', 'comments_link', 'short_name']\n",
    "df.head()\n",
    "\n",
    "# Save as CSV:\n",
    "df.to_csv(join(path_root, 'img_reddits.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_title</th>\n",
       "      <th>submission_link</th>\n",
       "      <th>comments_link</th>\n",
       "      <th>short_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>ITT: Things you hate that everyone else likes....</td>\n",
       "      <td>http://i.imgur.com/xvCP4.jpg</td>\n",
       "      <td>/r/funny/comments/eut3m/itt_things_you_hate_th...</td>\n",
       "      <td>t3_eut3m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WTF</td>\n",
       "      <td>This is the picture they're using to recruit p...</td>\n",
       "      <td>http://i.imgur.com/QDmzn.jpg</td>\n",
       "      <td>/r/WTF/comments/eut3k/this_is_the_picture_they...</td>\n",
       "      <td>t3_eut3k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funny</td>\n",
       "      <td>The Businessman Game - search Google Images fo...</td>\n",
       "      <td>http://www.customs.govt.nz/NR/rdonlyres/8F5ECF...</td>\n",
       "      <td>/r/funny/comments/eut35/the_businessman_game_s...</td>\n",
       "      <td>t3_eut35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffffffuuuuuuuuuuuu</td>\n",
       "      <td>two people, one shitter...</td>\n",
       "      <td>http://i.imgur.com/50VPz.png</td>\n",
       "      <td>/r/fffffffuuuuuuuuuuuu/comments/eut2n/two_peop...</td>\n",
       "      <td>t3_eut2n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>Wife is in bed early....CRAPFUCKSHIT...AAAAAAA...</td>\n",
       "      <td>http://i.imgur.com/94ZXF.jpg</td>\n",
       "      <td>/r/wow/comments/eut2j/wife_is_in_bed_earlycrap...</td>\n",
       "      <td>t3_eut2j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                   submission_title  \\\n",
       "0                funny  ITT: Things you hate that everyone else likes....   \n",
       "1                  WTF  This is the picture they're using to recruit p...   \n",
       "2                funny  The Businessman Game - search Google Images fo...   \n",
       "3  fffffffuuuuuuuuuuuu                         two people, one shitter...   \n",
       "4                  wow  Wife is in bed early....CRAPFUCKSHIT...AAAAAAA...   \n",
       "\n",
       "                                     submission_link  \\\n",
       "0                       http://i.imgur.com/xvCP4.jpg   \n",
       "1                       http://i.imgur.com/QDmzn.jpg   \n",
       "2  http://www.customs.govt.nz/NR/rdonlyres/8F5ECF...   \n",
       "3                       http://i.imgur.com/50VPz.png   \n",
       "4                       http://i.imgur.com/94ZXF.jpg   \n",
       "\n",
       "                                       comments_link short_name  \n",
       "0  /r/funny/comments/eut3m/itt_things_you_hate_th...   t3_eut3m  \n",
       "1  /r/WTF/comments/eut3k/this_is_the_picture_they...   t3_eut3k  \n",
       "2  /r/funny/comments/eut35/the_businessman_game_s...   t3_eut35  \n",
       "3  /r/fffffffuuuuuuuuuuuu/comments/eut2n/two_peop...   t3_eut2n  \n",
       "4  /r/wow/comments/eut2j/wife_is_in_bed_earlycrap...   t3_eut2j  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>ITT: Things you hate that everyone else likes....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WTF</td>\n",
       "      <td>This is the picture they're using to recruit p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funny</td>\n",
       "      <td>The Businessman Game - search Google Images fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffffffuuuuuuuuuuuu</td>\n",
       "      <td>two people, one shitter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>Wife is in bed early....CRAPFUCKSHIT...AAAAAAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                   submission_title\n",
       "0                funny  ITT: Things you hate that everyone else likes....\n",
       "1                  WTF  This is the picture they're using to recruit p...\n",
       "2                funny  The Businessman Game - search Google Images fo...\n",
       "3  fffffffuuuuuuuuuuuu                         two people, one shitter...\n",
       "4                  wow  Wife is in bed early....CRAPFUCKSHIT...AAAAAAA..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(join(path_root, 'img_reddits.csv'))\n",
    "\n",
    "df = df[['subreddit', 'submission_title']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def lemmatizer(string):\n",
    "    lst = []\n",
    "    doc = nlp(string)\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha and token.lemma_ != '-PRON-':  # TODO: fix, dirty!\n",
    "            lst.append(token.lemma_)\n",
    "            \n",
    "    return lst\n",
    "\n",
    "submission_titles = df['submission_title'].apply(lemmatizer)  # 1 min for 10k sentences!!\n",
    "df['submission_title'] = submission_titles\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['funny' 'WTF' 'fffffffuuuuuuuuuuuu' 'wow' 'AdviceAnimals' 'reddit.com'\n",
      " 'pics']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>submission_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>[itt, thing, hate, like, start]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WTF</td>\n",
       "      <td>[this, picture, recruit, police, brutality, ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funny</td>\n",
       "      <td>[the, businessman, game, search, google, image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fffffffuuuuuuuuuuuu</td>\n",
       "      <td>[people, shitter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>[wife, bed, early, crapfuckshit, aaaaaaa, sfw]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit                                   submission_title\n",
       "0                funny                    [itt, thing, hate, like, start]\n",
       "1                  WTF  [this, picture, recruit, police, brutality, ab...\n",
       "2                funny  [the, businessman, game, search, google, image...\n",
       "3  fffffffuuuuuuuuuuuu                                  [people, shitter]\n",
       "4                  wow     [wife, bed, early, crapfuckshit, aaaaaaa, sfw]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only subreddits with > min_posts posts:\n",
    "\n",
    "min_posts = 100\n",
    "\n",
    "top_subreddits = df['subreddit'].loc[(df['subreddit'].value_counts() > min_posts).values].unique()\n",
    "print(top_subreddits)\n",
    "\n",
    "df_top = df.loc[df.subreddit.isin(top_subreddits)]\n",
    "df_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-54c2fbecbecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcnts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_kws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AdviceAnimals'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mcnts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-162-54c2fbecbecf>\u001b[0m in \u001b[0;36mcount_words\u001b[0;34m(lst_of_strs, top_n)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mword_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst_of_strs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mword_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# top N most common keywords per subreddit:\n",
    "n_keywords = 10\n",
    "\n",
    "top_kws = df_top.groupby('subreddit').sum()\n",
    "\n",
    "def count_words(lst_of_strs, top_n=10):\n",
    "    #print(lst_of_strs)\n",
    "    word_counts = dict()\n",
    "    for word in lst_of_strs:\n",
    "        if word not in word_counts:\n",
    "            word_counts[word] = 1\n",
    "        else:\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "    # Sort:\n",
    "    word_counts = {word: word_counts[word] for word in sorted(word_counts, key=word_counts.get, reverse=True)}\n",
    "    \n",
    "    # top_n:\n",
    "    word_counts = {k: word_counts[k] for k in list(word_counts)[:top_n]}\n",
    "            \n",
    "    return word_counts\n",
    "\n",
    "# test:\n",
    "cnts = count_words(top_kws.loc['AdviceAnimals'])\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 33,\n",
       " 'like': 29,\n",
       " 'pic': 23,\n",
       " 'know': 22,\n",
       " 'this': 21,\n",
       " 'dad': 20,\n",
       " 'a': 19,\n",
       " 'think': 19,\n",
       " 'get': 19,\n",
       " 'new': 18}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts = count_words(top_kws.loc['funny'].values)\n",
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'itt': 1, 'thing': 1, 'hate': 1, 'like': 1, 'start': 1}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top['submission_title'].apply(count_words).loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hood': 17,\n",
       " 'dad': 17,\n",
       " 'sap': 16,\n",
       " 'the': 12,\n",
       " 'oblivious': 11,\n",
       " 'time': 10,\n",
       " 'fbf': 9,\n",
       " 'high': 9,\n",
       " 'new': 9,\n",
       " 'this': 8}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hood',\n",
       " 'dad',\n",
       " 'sap',\n",
       " 'the',\n",
       " 'oblivious',\n",
       " 'time',\n",
       " 'fbf',\n",
       " 'high',\n",
       " 'new',\n",
       " 'this',\n",
       " 'paranoid',\n",
       " 'pp',\n",
       " 'bad',\n",
       " 'parrot',\n",
       " 'know',\n",
       " 'mom',\n",
       " 'son',\n",
       " 'yo',\n",
       " 'frog',\n",
       " 'philosoraptor',\n",
       " 'think',\n",
       " 'way',\n",
       " 'soccer',\n",
       " 'clean',\n",
       " 'bachelor',\n",
       " 'grader',\n",
       " 'lonely',\n",
       " 'pug',\n",
       " 'say',\n",
       " 'wolf',\n",
       " 'penguin',\n",
       " 'happen',\n",
       " 'let',\n",
       " 'bro',\n",
       " 'all',\n",
       " 'successful',\n",
       " 'asian',\n",
       " 'father',\n",
       " 'foul',\n",
       " 'year',\n",
       " 'good',\n",
       " 'hot',\n",
       " 'hygiene',\n",
       " 'musically',\n",
       " 'awkward',\n",
       " 'girl',\n",
       " 'get',\n",
       " 'friend',\n",
       " 'school',\n",
       " 'see',\n",
       " 'socially',\n",
       " 'do',\n",
       " 'talk',\n",
       " 'influence',\n",
       " 'make',\n",
       " 'take',\n",
       " 'go',\n",
       " 'what',\n",
       " 'every',\n",
       " 'morning',\n",
       " 'day',\n",
       " 'workaholic',\n",
       " 'chick',\n",
       " 'love',\n",
       " 'no',\n",
       " 'one',\n",
       " 'store',\n",
       " 'at',\n",
       " 'like',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'nihilism',\n",
       " 'narwhal',\n",
       " 'need',\n",
       " 'why',\n",
       " 'courage',\n",
       " 'not',\n",
       " 'phone',\n",
       " 'man',\n",
       " 'create',\n",
       " 'gaming',\n",
       " 'gopher',\n",
       " 'trouble',\n",
       " 'fuck',\n",
       " 'obvious',\n",
       " 'use',\n",
       " 'image',\n",
       " 'niger',\n",
       " 'just',\n",
       " 'case',\n",
       " 'musician',\n",
       " 'window',\n",
       " 'bitch',\n",
       " 'finish',\n",
       " 'dinner',\n",
       " 'happy',\n",
       " 'expectations',\n",
       " 'fix',\n",
       " 'mind',\n",
       " 'attempt',\n",
       " 'imma',\n",
       " 'report',\n",
       " 'reddit',\n",
       " 'hear',\n",
       " 'last',\n",
       " 'alcoholic',\n",
       " 'alligator',\n",
       " 'stand',\n",
       " 'second',\n",
       " 'big',\n",
       " 'of',\n",
       " 'iron',\n",
       " 'maiden',\n",
       " 'movie',\n",
       " 'night',\n",
       " 'today',\n",
       " 'party',\n",
       " 'text',\n",
       " 'crack',\n",
       " 'watch',\n",
       " 'pretty',\n",
       " 'game',\n",
       " 'stop',\n",
       " 'rollin',\n",
       " 'album',\n",
       " 'wow',\n",
       " 'hell',\n",
       " 'baby',\n",
       " 'sure',\n",
       " 'um',\n",
       " 'want',\n",
       " 'ask',\n",
       " 'bill',\n",
       " 'restaurant',\n",
       " 'job',\n",
       " 'choice',\n",
       " 'never',\n",
       " 'insanity',\n",
       " 'call',\n",
       " 'well',\n",
       " 'fair',\n",
       " 'pause',\n",
       " 'woop',\n",
       " 'order',\n",
       " 'haunt',\n",
       " 'guy',\n",
       " 'plan',\n",
       " 'more',\n",
       " 'help',\n",
       " 'oh',\n",
       " 'sad',\n",
       " 'on',\n",
       " 'roll',\n",
       " 'life',\n",
       " 'itty',\n",
       " 'bitty',\n",
       " 'gas',\n",
       " 'ass',\n",
       " 'grocery',\n",
       " 'compilation',\n",
       " 'hang',\n",
       " 'tell',\n",
       " 'boyfriend',\n",
       " 'platypus',\n",
       " 'put',\n",
       " 'that',\n",
       " 'post',\n",
       " 'black',\n",
       " 'community',\n",
       " 'sock',\n",
       " 'tech',\n",
       " 'support',\n",
       " 'horror',\n",
       " 'games',\n",
       " 'police',\n",
       " 'trust',\n",
       " 'word',\n",
       " 'lot',\n",
       " 'stranger',\n",
       " 'hit',\n",
       " 'reason',\n",
       " 'imitate',\n",
       " 'hipster',\n",
       " 'drinking',\n",
       " 'moderation',\n",
       " 'label',\n",
       " 'proof',\n",
       " 'pudding',\n",
       " 'cumsock',\n",
       " 'dog',\n",
       " 'pelvis',\n",
       " 'thrust',\n",
       " 'spoiled',\n",
       " 'milk',\n",
       " 'page',\n",
       " 'intentionally',\n",
       " 'leave',\n",
       " 'blank',\n",
       " 'internet',\n",
       " 'escalation',\n",
       " 'now',\n",
       " 'still',\n",
       " 'home',\n",
       " 'fake',\n",
       " 'maneuver',\n",
       " 'confuse',\n",
       " 'yeah',\n",
       " 'open',\n",
       " 'drug',\n",
       " 'freshly',\n",
       " 'cut',\n",
       " 'grass',\n",
       " 'hard',\n",
       " 'week',\n",
       " 'omg',\n",
       " 'beetles',\n",
       " 'med',\n",
       " 'judas',\n",
       " 'priest',\n",
       " 'violent',\n",
       " 'femmes',\n",
       " 'shopping',\n",
       " 'always',\n",
       " 'west',\n",
       " 'side',\n",
       " 'actually',\n",
       " 'accurate',\n",
       " 'birthday',\n",
       " 'disregard',\n",
       " 'jews',\n",
       " 'come',\n",
       " 'crystal',\n",
       " 'castles',\n",
       " 'an',\n",
       " 'error',\n",
       " 'question',\n",
       " 'sexuality',\n",
       " 'meet',\n",
       " 'neighbour',\n",
       " 'bout',\n",
       " 'drunk',\n",
       " 'whistle',\n",
       " 'another',\n",
       " 'resolution',\n",
       " 'heaf',\n",
       " 'state',\n",
       " 'dubstep',\n",
       " 'how',\n",
       " 'official',\n",
       " 'npc',\n",
       " 'celebrate',\n",
       " 'squirt',\n",
       " 'anal',\n",
       " 'cock',\n",
       " 'wet',\n",
       " 'minefield',\n",
       " 'cvs',\n",
       " 'system',\n",
       " 'a',\n",
       " 'down',\n",
       " 'ayo',\n",
       " 'atm',\n",
       " 'plow',\n",
       " 'homo',\n",
       " 'rimjob',\n",
       " 'sums',\n",
       " 'childhood',\n",
       " 'hate',\n",
       " 'fly',\n",
       " 'probably',\n",
       " 'haircut',\n",
       " 'feedback',\n",
       " 'loop',\n",
       " 'frustration',\n",
       " 'anyone',\n",
       " 'send',\n",
       " 'in',\n",
       " 'palm',\n",
       " 'homeboy',\n",
       " 'korn',\n",
       " 'indo',\n",
       " 'brb',\n",
       " 'travel',\n",
       " 'meowing',\n",
       " 'sunday',\n",
       " 'hustlin',\n",
       " 'pink',\n",
       " 'floyd',\n",
       " 'oral',\n",
       " 'yiddish',\n",
       " 'language',\n",
       " 'wall',\n",
       " 'double',\n",
       " 'piss',\n",
       " 'stream',\n",
       " 'check',\n",
       " 'reverse',\n",
       " 'true',\n",
       " 'chill',\n",
       " 'prodigy',\n",
       " 'cowboy',\n",
       " 'blood',\n",
       " 'type',\n",
       " 'sporting',\n",
       " 'event',\n",
       " 'introduct',\n",
       " 'either',\n",
       " 'starve',\n",
       " 'homosexuality',\n",
       " 'peeing',\n",
       " 'be',\n",
       " 'because',\n",
       " 'play',\n",
       " 'oblvious',\n",
       " 'law',\n",
       " 'regulate',\n",
       " 'right',\n",
       " 'rough',\n",
       " 'nowadays',\n",
       " 'really',\n",
       " 'paystub',\n",
       " 'stub',\n",
       " 'car',\n",
       " 'dark',\n",
       " 'great',\n",
       " 'toast',\n",
       " 'ma',\n",
       " 'water',\n",
       " 'revenge',\n",
       " 'fox',\n",
       " 'blonde',\n",
       " 'offer',\n",
       " 'thought',\n",
       " 'office',\n",
       " 'pantera',\n",
       " 'ponder',\n",
       " 'self',\n",
       " 'loathing',\n",
       " 'break',\n",
       " 'inception',\n",
       " 'graveyard',\n",
       " 'shift',\n",
       " 'sing',\n",
       " 'starbuck',\n",
       " 'goodbye',\n",
       " 'world',\n",
       " 'baked',\n",
       " 'vampire',\n",
       " 'weekend',\n",
       " 'locker',\n",
       " 'feel',\n",
       " 'dumb',\n",
       " 'daily',\n",
       " 'basis',\n",
       " 'cook',\n",
       " 'sticky',\n",
       " 'runny',\n",
       " 'rain',\n",
       " 'shine',\n",
       " 'appreciate',\n",
       " 'pursue',\n",
       " 'career',\n",
       " 'bachelorish',\n",
       " 'mock',\n",
       " 'hairstyle',\n",
       " 'ever',\n",
       " 'nocturnal',\n",
       " 'epiphany',\n",
       " 'out',\n",
       " 'relief',\n",
       " 'damn',\n",
       " 'duty',\n",
       " 'brand',\n",
       " 'tim',\n",
       " 'therapy',\n",
       " 'download',\n",
       " 'discography',\n",
       " 'perfect',\n",
       " 'involved',\n",
       " 'math',\n",
       " 'pop',\n",
       " 'tart',\n",
       " 'dvd',\n",
       " 'unreliable',\n",
       " 'johnny',\n",
       " 'depp',\n",
       " 'underwear',\n",
       " 'bright',\n",
       " 'eye',\n",
       " 'discover',\n",
       " 'also',\n",
       " 'social',\n",
       " 'success',\n",
       " 'forever',\n",
       " 'alone',\n",
       " 'contraception',\n",
       " 'movin',\n",
       " 'weight',\n",
       " 'flushing',\n",
       " 'sly',\n",
       " 'steve',\n",
       " 'submit',\n",
       " 'observations',\n",
       " 'yeesh',\n",
       " 'retirement',\n",
       " 'efficient',\n",
       " 'killing',\n",
       " 'awesome',\n",
       " 'gat',\n",
       " 'hello',\n",
       " 'there',\n",
       " 'schadenfreude',\n",
       " 'little',\n",
       " 'hour',\n",
       " 'rule',\n",
       " 'own',\n",
       " 'yacht',\n",
       " 'sick',\n",
       " 'shit',\n",
       " 'jesus',\n",
       " 'hmm',\n",
       " 'browsing',\n",
       " 'adviceanimal',\n",
       " 'point',\n",
       " 'quality',\n",
       " 'carnevale',\n",
       " 'tid',\n",
       " 'envelope',\n",
       " 'joint',\n",
       " 'diagnosis',\n",
       " 'tbf',\n",
       " 'weekly',\n",
       " 'schedule',\n",
       " 'boat',\n",
       " 'hall',\n",
       " 'especially',\n",
       " 'station',\n",
       " 'sor',\n",
       " 'dawn',\n",
       " 'later',\n",
       " 'into',\n",
       " 'pit',\n",
       " 'fire',\n",
       " 'hated',\n",
       " 'cap',\n",
       " 'heart',\n",
       " 'pound',\n",
       " 'bang',\n",
       " 'hoe',\n",
       " 'builder',\n",
       " 'too',\n",
       " 'toe',\n",
       " 'hurt',\n",
       " 'from',\n",
       " 'kick',\n",
       " 'huge',\n",
       " 'collection',\n",
       " 'will',\n",
       " 'cancel',\n",
       " 'effect',\n",
       " 'limit',\n",
       " 'instant',\n",
       " 'karma',\n",
       " 'instinct',\n",
       " 'coffee',\n",
       " 'binge',\n",
       " 'cop',\n",
       " 'killer',\n",
       " 'waste',\n",
       " 'god',\n",
       " 'hey',\n",
       " 'everytime',\n",
       " 'lego',\n",
       " 'blondie',\n",
       " 'indie',\n",
       " 'rock',\n",
       " 'free',\n",
       " 'fallin',\n",
       " 'helpful',\n",
       " 'tyler',\n",
       " 'durden',\n",
       " 'unfinished',\n",
       " 'business',\n",
       " 'bookstore',\n",
       " 'peni',\n",
       " 'amidoingitright',\n",
       " 'spouse',\n",
       " 'satisfied',\n",
       " 'worth',\n",
       " 'picture',\n",
       " 'demand',\n",
       " 'funny',\n",
       " 'bull',\n",
       " 'amidoingthisright',\n",
       " 'nighter',\n",
       " 'weasel',\n",
       " 'people',\n",
       " 'fit',\n",
       " 'pain',\n",
       " 'express',\n",
       " 'taste',\n",
       " 'fridge',\n",
       " 'mediocre',\n",
       " 'www',\n",
       " 'comment',\n",
       " 'swan',\n",
       " 'laugh',\n",
       " 'salad',\n",
       " 'woman',\n",
       " 'wait',\n",
       " 'kinect',\n",
       " 'ocd',\n",
       " 'otter',\n",
       " 'whateva',\n",
       " 'chedda',\n",
       " 'counter',\n",
       " 'strike',\n",
       " 'scrim',\n",
       " 'team',\n",
       " 'tv',\n",
       " 'indian',\n",
       " 'al',\n",
       " 'kominas',\n",
       " 'house',\n",
       " 'better',\n",
       " 'toyota',\n",
       " 'babysitter',\n",
       " 'card',\n",
       " 'bono',\n",
       " 'pissed',\n",
       " 'receive',\n",
       " 'junk',\n",
       " 'mail',\n",
       " 'jerk',\n",
       " 'giggle',\n",
       " 'everyone',\n",
       " 'and',\n",
       " 'course',\n",
       " 'fan',\n",
       " 'vote',\n",
       " 'subbredit',\n",
       " 'blink',\n",
       " 'everyday',\n",
       " 'keep',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'lazy',\n",
       " 'encounter',\n",
       " 'negro',\n",
       " 'dedication',\n",
       " 'ordinary',\n",
       " 'muslim',\n",
       " 'set',\n",
       " 'surprise',\n",
       " 'gasp',\n",
       " 'prison',\n",
       " 'cooking',\n",
       " 'monday',\n",
       " 'which',\n",
       " 'hybrid',\n",
       " 'wonder',\n",
       " 'suck',\n",
       " 'cw',\n",
       " 'chat',\n",
       " 'thank',\n",
       " 'sandwich',\n",
       " 'solution',\n",
       " 'hero',\n",
       " 'emachine',\n",
       " 'ball',\n",
       " 'itch',\n",
       " 'rapin',\n",
       " 'everybody',\n",
       " 'resort',\n",
       " 'back',\n",
       " 'feline',\n",
       " 'focus',\n",
       " 'win',\n",
       " 'hold',\n",
       " 'breath',\n",
       " 'fatty',\n",
       " 'fatboy',\n",
       " 'laziness',\n",
       " 'bus',\n",
       " 'classic',\n",
       " 'archimedes',\n",
       " 'memegenerator',\n",
       " 'host',\n",
       " 'undearwear',\n",
       " 'unpack',\n",
       " 'clothe',\n",
       " 'kitchen',\n",
       " 'utensil',\n",
       " 'late',\n",
       " 'try',\n",
       " 'sneaky',\n",
       " 'end',\n",
       " 'fail',\n",
       " 'read',\n",
       " 'detail',\n",
       " 'separate',\n",
       " 'c',\n",
       " 'unfamiliar',\n",
       " 'number',\n",
       " 'college',\n",
       " 'sit',\n",
       " 'crush']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(x.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdviceAnimals</th>\n",
       "      <td>[gaming, gopher, trouble, horror, games, fuck,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTF</th>\n",
       "      <td>[this, picture, recruit, police, brutality, ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffffffuuuuuuuuuuuu</th>\n",
       "      <td>[people, shitter, how, lose, weight, butter, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>[itt, thing, hate, like, start, the, businessm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pics</th>\n",
       "      <td>[if, die, today, feel, satisfied, drunk, sovie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit.com</th>\n",
       "      <td>[wife, bed, early, crapfuckshit, aaaaaaa, sfw,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wow</th>\n",
       "      <td>[wife, bed, early, crapfuckshit, aaaaaaa, sfw,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      submission_title\n",
       "subreddit                                                             \n",
       "AdviceAnimals        [gaming, gopher, trouble, horror, games, fuck,...\n",
       "WTF                  [this, picture, recruit, police, brutality, ab...\n",
       "fffffffuuuuuuuuuuuu  [people, shitter, how, lose, weight, butter, e...\n",
       "funny                [itt, thing, hate, like, start, the, businessm...\n",
       "pics                 [if, die, today, feel, satisfied, drunk, sovie...\n",
       "reddit.com           [wife, bed, early, crapfuckshit, aaaaaaa, sfw,...\n",
       "wow                  [wife, bed, early, crapfuckshit, aaaaaaa, sfw,..."
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apples 8566208034543834098 apple False\n",
      "and 2283656566040971221 and True\n",
      "oranges 2208928596161743350 orange False\n",
      "are 10382539506755952630 be True\n",
      "similar 18166476740537071113 similar False\n",
      ". 12646065887601541794 . False\n",
      "Boots 9918665227421442029 boot False\n",
      "and 2283656566040971221 and True\n",
      "hippos 6542994350242320795 hippo False\n",
      "are 10382539506755952630 be True\n",
      "n't 447765159362469301 not False\n",
      ". 12646065887601541794 . False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "doc = nlp(u\"Apples and oranges are similar. Boots and hippos aren't.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.lemma, token.lemma_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'en_core_web_sm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8a5aa70d40b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'en_core_web_sm'"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
